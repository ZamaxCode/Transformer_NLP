{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "50908fc9-8eaf-42d1-a82b-78506e5d6f1d",
   "metadata": {},
   "source": [
    "# Multi Head Attention"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dc5cc8f-58ff-4f4a-8be5-6280b8f42268",
   "metadata": {},
   "source": [
    "### Terminos nuevos:\n",
    "* h - heads (cada cabeza representa una capa de paralelizacion de nuestro scaled dot-product attention)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc3642ed-9349-4482-bf28-676dbf406b76",
   "metadata": {},
   "source": [
    "El multi-head attention es una version escalada del self dot-product attention que se vio anteriormente, solo que este utiliza varias capas corriendo en paralelo.\n",
    "\n",
    "<img src=\"./images/multi_head_attention.png\" alt=\"scaled_dot_prod_attent\" width=\"200\" height=\"auto\"> <img src=\"./images/mha_formula.png\" alt=\"scaled_dot_prod_attent\" width=\"500\" height=\"auto\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b038fcbc-2f09-44f0-984c-2d4c8dac2163",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "08e859fd-cc69-434c-a00a-08712e58e449",
   "metadata": {},
   "outputs": [],
   "source": [
    "phrase = \"Hola mi nombre es Alex\"\n",
    "input_phrase = phrase.split(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "522680a5-8ea5-4267-98f4-ccb770f4e5fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence_len = len(input_phrase)\n",
    "batch_size = 1\n",
    "input_dim = 512\n",
    "d_model = 512\n",
    "x = torch.randn((batch_size, sequence_len, input_dim))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "33a38ee7-ba7a-4d35-9d2b-8a2b4e602aa9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 5, 512])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "65579542-26a1-4185-8f0e-ac4c5292515f",
   "metadata": {},
   "outputs": [],
   "source": [
    "qkv_layer = nn.Linear(input_dim, 3*d_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f5e8c704-1a2f-4d94-8f14-0bd507113940",
   "metadata": {},
   "outputs": [],
   "source": [
    "qkv = qkv_layer(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4c01190d-d9cc-4ef5-a124-580dccd7d0df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 5, 1536])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qkv.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4547f091-3603-4319-b26b-856e5602ce0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "h = 8\n",
    "h_dim = d_model // h\n",
    "qkv = qkv.reshape(batch_size, sequence_len, h, 3*h_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9eeb7982-e6b9-4a89-a473-66cb4b9bb231",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 5, 8, 192])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qkv.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "942ed95f-4d4f-43d6-b9a2-ed3ebe20da54",
   "metadata": {},
   "outputs": [],
   "source": [
    "qkv = qkv.permute(0,2,1,3) #batch, num_heads, sequence_len, 3*head_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fa003221-e383-4781-b972-787a50cf604c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 8, 5, 192])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qkv.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2b3c84b8-3d5f-4c8f-b492-823885e130a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 8, 5, 64])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q, k, v = qkv.chunk(3, dim=-1)\n",
    "q.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35071f5a",
   "metadata": {},
   "source": [
    "Una vez que tenemos separados nuestros datos en multi-heads para q, k y v, ahora vamos a utilizar las funciones que se crearon de para calcular la atencion por cada una de nuestras heads.\n",
    "\n",
    "<img src=\"./images/attention.png\" alt=\"attention formula\" width=\"400\" height=\"auto\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "38924c3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def scaled_dot_product(Q, V, K, Use_Mask=False):\n",
    "    d_k = K.shape[-1]\n",
    "    scaled = torch.matmul(Q, K.transpose(-1,-2))/math.sqrt(d_k)\n",
    "    if Use_Mask:\n",
    "        mask = torch.full(scaled.size(), float('-inf'))\n",
    "        mask = torch.triu(mask, diagonal=1)\n",
    "        scaled += mask\n",
    "    attention = F.softmax(scaled, dim=-1)\n",
    "    out = torch.matmul(attention, V)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "63b03175-19a8-4361-a6c6-6dacc2e47fc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = scaled_dot_product(Q=q, V=v, K=k, Use_Mask=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "ba678940",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 8, 5, 64])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "619ae9f1",
   "metadata": {},
   "source": [
    "Con este vector de salida que nos arrojo la funcion de scaled_dot_product tenemos que los valores corresponden a:\n",
    "1 -> batch size\n",
    "8 -> heads\n",
    "5 -> sequence len\n",
    "64 -> head_dim\n",
    "\n",
    "Por lo que ahora toca concatenar todos los valores de las heads de nuestro modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "715dce6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "concat = res.reshape(batch_size, sequence_len, h*h_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "9b857fda",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 5, 512])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "concat.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73757419",
   "metadata": {},
   "source": [
    "Teniendo esto, ahora toca el ultimo paso de multi-head attention que es pasar el resultado a una funcion lineal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "4706d828",
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_layer = nn.Linear(d_model, d_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "c6d19cda",
   "metadata": {},
   "outputs": [],
   "source": [
    "out = linear_layer(concat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "d6db68df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 5, 512])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
